<!-- <!DOCTYPE html> -->
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Jiaxun Cui</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Le styles -->
    <link href="./assets_files/bootstrap.min.css" rel="stylesheet">
    <link href="./assets_files/bootstrap-responsive.min.css" rel="stylesheet">
    <link href="./assets_files/yangqing.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
    <script src="assets/js/html5shiv.js"></script>
    <![endif]-->
    <link rel="icon" href="./assets_files/jc.png">
</head>

<div class="visible-phone" id="blackBar">
    <a href="#top">About</a>
    <!--<a href="#research">Research</a>-->
    <a href="#projects">Projects</a>
    <!--<a href="#teaching">Teaching</a>-->
    <a target="_blank"
       href="https://drive.google.com/file/d/1BcnqvWtokuEZF-5VnSByx3AY6_UHWhMm/view?usp=sharing">CV</a>
</div>

<body>

<div class="container span3 hidden-phone">
    <div id="floating_sidebar" class="span3">
        <!-- We use a fancy nav bar if there is enough space -->
        <!--<hr class="hidden-phone">-->
        <br>
        <ul class="nav nav-list bs-docs-sidenav hidden-phone">
            <li><a href="#top">About</a></li>
            <!--<li><a href="#research">Research</a></li>-->
            <li><a href="#projects">Projects</a></li>
            <!--<li><a href="#teaching">Teaching</a></li>-->
            <li><a target="_blank"
                   href="https://drive.google.com/file/d/1BcnqvWtokuEZF-5VnSByx3AY6_UHWhMm/view?usp=sharing">CV</a>
            </li>
        </ul>
        <hr class="hidden-phone">
        <div class="text-center hidden-phone">
            <img src="assets_files/me2.png" alt="photo" class="logo-image">
            <br><br>
            cuijiaxun AT utexas DOT edu <br>
        </div>

        <!-- Otherwise, we simply use a flat list of links -->
    </div>
</div>


<div class="container">

    <div class="row">

        <div class="span9">
            <br>
            <h3>
                Jiaxun Cui (崔佳勋)
            </h3>
            <h5>
                cuijiaxun AT utexas DOT edu
            / <a target="_blank" 
                 href="https://github.com/cuijiaxun">GitHub</a>
            / <a target="_blank"
                 href="https://drive.google.com/file/d/1BcnqvWtokuEZF-5VnSByx3AY6_UHWhMm/view?usp=sharing">CV</a>
            / <a target="_blank"
                 href="https://scholar.google.com/citations?user=SwEYj9YAAAAJ&hl=zh-CN&oi=ao" >Google Scholar</a>
            / <a target="_blank"
                 href="https://www.linkedin.com/in/cuijiaxun/" >LinkedIn</a>

            </h5>
            <!-- Do I want to show a pic on the phone screen?
            <div class="text-center visible-phone">
                <img src="assets/img/Yihui.png" alt="photo" width="150px"/>
            </div>
            -->
            <a class="visible-phone pull-left" href="https://cuijiaxun.github.io">
                <img class="media-object" src="assets_files/me2.png" width="96px" style="margin: 0px 10px">
            </a>
            <p>
            I'm a final year Electrical and Computer Engineering PhD student at <a href="https://www.utexas.edu/">The University of Texas at Austin</a>, with my ambitious goal of building a general AI for human benefits. I am privileged to work with Prof.<a href="https://www.cs.utexas.edu/~pstone/">Peter Stone</a> at the <a href="https://www.cs.utexas.edu/~pstone/">Learning Agent Research Group (LARG)</a>. Priviously I completed my undergraduate study at <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a> with a major in Mechanical Engineering (Robotics). I broadened my practical AI skillset through an enriching internship under <a target="_blank" href="https://www.linkedin.com/in/xiaomeng-yang-356a976b/">Xiaomeng Yang</a> and <a target="_blank" href="https://yuandong-tian.com/">Yuandong Tian</a> at <a target="_blank" href="https://ai.facebook.com/">Meta FAIR Labs</a> in Summer 2022. Besides research, I enjoy Tennis, Cello and Rap Music.
            </p>            
            <!--
             *** Research ***
            -->
            <h3>
                <a name="research"></a> Research
            </h3>
            <p>
                My current research interests include:
            </p><ul>
                <li> Multi-agent (Reinforcement) Learning
                </li><li> Game Theory
                </li><li> Robotics
                </li></ul>
            <p></p>
            <p>
            I coordinate <a target="_blank" href="https://www.cs.utexas.edu/~rlrg/website.md.html">Reinforcement Learning Reading Group (RLRG)</a> at UT.
            </p>
            <p>
            Academic Services: reviewer for NeurIPS, ICML, ICLR, AAMAS, CVPR, RA-L
            </p>


            <!--
             *** Projects ***
            -->
            <h3>
                <a name="projects"></a> Projects
            </h3>
            <div class="media">
                <a name="pts" class="pull-left">
                    <img class="media-object" src="./assets/talkingvehicles.png" width="120px" height="120px">
                </a>
                <div class="media-body">
                    <p class="media-heading"><strong>
                        Talking Vehicles: Cooperative Driving via Natural Language
                    </strong>
                    <br> <strong>Jiaxun Cui</strong>, <a>Chen Tang</a>, <a>Jarrett Holtz</a>, <a>Janice Nguyen</a>, <a>Alessandro G. Allievi</a>, <a>Hang Qiu</a>, <a href="https://www.cs.utexas.edu/~pstone/">Peter Stone</a>
                    <br><em> <a href="https://multiagents.org/workshop">WMAC 2025</a> - AAAI Workshop on Advancing LLM-Based Multi-Agent Collaboration (<strong>Oral</strong>), 2025</em>
                    <br><a href="https://multiagents.org/2025_artifacts/talking_vehicles_cooperative_driving_via_natural_language.pdf" > [paper] </a> <a href="https://github.com"> [code] </a> <a hred="https://multiagents.org/2025_talks/talk_talking_vehicles_cooperative_driving_via_natural_language.pdf"> [slides] </a>
                    </p>
                    <p class="abstract-text">
                    We propose a novel approach to cooperative driving using natural language communication. Our method leverages large language models (LLMs) to facilitate communication between vehicles, enabling them to share information and coordinate their actions effectively. We evaluate our approach in a simulated driving environment, demonstrating its potential to enhance safety and efficiency in autonomous driving scenarios.
                    </p>
                </div>
            </div>
            <div class="media">
                <a name="pts" class="pull-left">
                    <img class="media-object" src="./assets/l-brdiv.png" width="120px" height="120px">
                </a>
                <div class="media-body">
                    <p class="media-heading"><strong>
                        Minimum Coverage Sets for Training Robust Ad Hoc Teamwork Agents
                    </strong>
                    <br><a href="https://raharrasy.github.io/">Arrasy Rahman</a>, <strong>Jiaxun Cui</strong>, <a href="https://www.cs.utexas.edu/~pstone/">Peter Stone</a>
                    <br><em> Annual AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2024</em>
                    <br><a href="https://openreview.net/forum?id=CDlHZ78-Xzi" > [paper] </a> <a href="https://github.com/facebookresearch/macta"> [code] </a>
                    </p>
                    <p class="abstract-text">
                    In this work, we first propose that maximizing an AHT agent's robustness requires it to emulate policies in the minimum coverage set (MCS), the set of best-response policies to any partner policies in the environment. We then introduce the L-BRDiv algorithm that generates a set of teammate policies that, when used for AHT training, encourage agents to emulate policies from the MCS. L-BRDiv works by solving a constrained optimization problem to jointly train teammate policies for AHT training and approximating AHT agent policies that are members of the MCS. 
                    </p>
                </div>
            </div>

            <div class="media">
                <a name="pts" class="pull-left">
                    <img class="media-object" src="./assets/macta_logo.png" width="120px" height="120px">
                </a>
                <div class="media-body">
                    <p class="media-heading"><strong>
                             MACTA: A Multi-agent Reinforcement Learning Approach for Cache Timing Attacks and Detection 
                    </strong>
                    <br><strong>Jiaxun Cui</strong>, <a target="_blank" href="https://www.linkedin.com/in/xiaomeng-yang-356a976b/">Xiaomeng Yang*</a>, <a href="https://mulongluo.me/">Mulong Luo*</a>, Geunbae Lee*, <a href="https://www.cs.utexas.edu/~pstone/">Peter Stone</a>, <a href="https://hsienhsinlee.github.io/">Hsien-Hsin S Lee</a>, <a href="https://www.seas.upenn.edu/~leebcc/">Benjamin Lee</a>, <a href="https://tsg.ece.cornell.edu/people/g-edward-suh/">G Edward Suh</a>, <a href="https://computing.ece.vt.edu/~wenjiex/">Wenjie Xiong*</a>, <a target="_blank" href="https://yuandong-tian.com/">Yuandong Tian*</a> 
                    <br><em>International Conference on Learning Representations (<strong>ICLR</strong>), 2023</em>
                    <br><a href="https://openreview.net/forum?id=CDlHZ78-Xzi" > [paper] </a> <a href="https://github.com/facebookresearch/macta"> [code] </a>
                    </p>
                    <p class="abstract-text">
                   MACTA detectors can generalize to a heuristic attack not exposed in training with a 97.8% detection rate and reduce the attack bandwidth of adaptive attackers by 20% on average. In the meantime, MACTA attackers are qualitatively more effective than other attacks studied, and the average evasion rate of MACTA attackers against an unseen state-of-the-art detector can reach up to 99%. 
                    </p>
                </div>
            </div>
    
            <div class="media">
                <a name="pts" class="pull-left">
                    <img class="media-object" src="./assets/autocast_logo.png" width="120px" height="120px">
                </a>
                <div class="media-body">
                    <p class="media-heading"><strong>
                             Coopernaut: End-to-End Driving with Cooperative Perception for Networked Vehicles
                    </strong>
                    <br><strong>Jiaxun Cui*</strong>, <a href="https://web.stanford.edu/~hangqiu/">Hang Qiu*</a>, <a href="https://www.cs.utexas.edu/~dchen/">Dian Chen</a>, <a href="https://www.cs.utexas.edu/~pstone/">Peter Stone</a>, <a href="https://www.cs.utexas.edu/~yukez/">Yuke Zhu</a> 
                    <br><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022</em>
                    <br><a href="https://arxiv.org/abs/2205.02222" > [paper] </a> <a href="https://ut-austin-rpl.github.io/Coopernaut/"> [project page] </a> <a href="https://github.com/UT-Austin-RPL/Coopernaut"> [code] </a>
                    </p>
                    <p class="abstract-text">
                        There are dangerous scenarios where single optical based sensor are occluded. We develop a series of benchmark scenarios in the CARLA simulator where cooperative perception can make big difference in the decisions made by the autonomous vehicles.        
                    </p>
                </div>
            </div>


            <div class="media">
                <a name="pts" class="pull-left">
                    <img class="media-object" src="./assets/mahjong_logo.png" width="120px" height="120px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             Meta-Learning for Multiround Chinese Standard Mahjong Game
                     </strong>
                    </p>
                    <p class="abstract-text">
                           Chinese Standard Mahjong Game is a 4-player zero-sum imperfect information game. While in the formal competitions of the mahjong game, a player will compete with the other opponents for a fixed number of rounds, and then the relative cumulative reward/points are compared. It is no longer a zero-sum game and the agents only care about a relative better performance than other players. This competition mechanism induces multi-round tactics. For example, an agent may play conservatively to secure its ranking or play riskly when it is left behind.
                    </p>
                </div>
            </div>


                    <div class="media">
                <a name="pts" class="pull-left">
                    <img class="media-object" src="./assets/flow_logo.png" width="120px" height="120px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             Scalable Multiagent Driving Policies For Reducing Traffic Congestion
                        </strong>
                        <br><strong> Jiaxun Cui</strong>, <a href="https://williammacke.github.io/">William Macke</a>, <a href="https://sites.google.com/site/harelyedidsion/Home">Harel Yedidsion</a>, <a href="">Aastha Goyal</a>, <a href="https://www.cs.utexas.edu/~urieli/">Daniel Urielli</a>, <a href="https://www.cs.utexas.edu/~pstone/">Peter Stone</a>
                        <br><em> Oral Presentation, International Conference on Autonomous Agents and Multiagent Systems (<strong>AAMAS</strong>), 2021</em>
                        <br>
                        <a target="_blank" href="https://arxiv.org/abs/2103.00058"> [paper] </a>
                        <a target="_blank" href="https://github.com/cuijiaxun/MITC-Project"> [code] </a>
                    </p>
                    <p class="abstract-text">
                        In the mordern highway system, the issue of conjestions brings inefficiency in traffic throughput and also cause waste of energy consumption. In this project, we employed deep Reinforcement Learning method to alleviate stop-and-go waves arosed from merging. We explored two aspects of multi-agent learning: Centralized and Distributed. Evaluting only average speed and throughput efficiency could be toublesome because the two metrics may not be improved at the same time. Thus, we developed a new metric: time delay for a certain number of vehicles to enter and exit the networks.                 
                    </p>
                </div>
            </div>
            <!-- Footer
            ================================================== -->
            <hr>
            <footer class="footer">
                 <div class="row">
                    <div class="span12">
                        <p>
                            Disciplina praesidium civitatis
                        </p>
                    </div>
                </div>

            </footer>

        </div>
    </div>
</div>
</body>
</html>

<!-- Le javascript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<!--
    <script type="text/javascript" src="http://platform.twitter.com/widgets.js"></script>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script src="assets/js/bootstrap-transition.js"></script>
    <script src="assets/js/bootstrap-alert.js"></script>
    <script src="assets/js/bootstrap-modal.js"></script>
    <script src="assets/js/bootstrap-dropdown.js"></script>
    <script src="assets/js/bootstrap-scrollspy.js"></script>
    <script src="assets/js/bootstrap-tab.js"></script>
    <script src="assets/js/bootstrap-tooltip.js"></script>
    <script src="assets/js/bootstrap-popover.js"></script>
    <script src="assets/js/bootstrap-button.js"></script>
    <script src="assets/js/bootstrap-collapse.js"></script>
    <script src="assets/js/bootstrap-carousel.js"></script>
    <script src="assets/js/bootstrap-typeahead.js"></script>
    <script src="assets/js/bootstrap-affix.js"></script>
    <script src="assets/js/holder/holder.js"></script>
    <script src="assets/js/application.js"></script>
-->
